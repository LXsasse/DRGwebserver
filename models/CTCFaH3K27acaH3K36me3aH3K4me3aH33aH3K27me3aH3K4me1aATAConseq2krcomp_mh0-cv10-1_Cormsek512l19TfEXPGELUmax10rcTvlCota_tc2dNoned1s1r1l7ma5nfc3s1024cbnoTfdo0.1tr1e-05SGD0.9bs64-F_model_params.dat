training : True
_parameters : OrderedDict()
_buffers : OrderedDict()
_non_persistent_buffers_set : set()
_backward_hooks : OrderedDict()
_is_full_backward_hook : None
_forward_hooks : OrderedDict()
_forward_pre_hooks : OrderedDict()
_state_dict_hooks : OrderedDict()
_load_state_dict_pre_hooks : OrderedDict()
_load_state_dict_post_hooks : OrderedDict()
_modules : OrderedDict()
seed : 0
verbose : True
loss_function : Correlationmse
validation_loss : Correlationdata
loss_weights : 1
val_loss_weights : 1
kwargs : {'finetuning_patience': 2, 'finetuning_rounds': 3, 'finetuning_rate': 0.05}
keepmodel : True
n_features : 4
reverse_complement : True
complement_pool : max
l_seqs : 2000
n_classes : [67, 93, 77, 81, 56, 94, 80, 81]
shift_sequence : None
random_shift : False
reverse_sign : False
smooth_onehot : 0
restart : False
adjust_lr : F
kernel_lr : None
num_kernels : 512
l_kernels : 19
kernel_bias : True
kernel_function : EXP
nlconv : False
nlconv_position_wise : False
nlconv_fclayer : None
nlconv_explicit : False
nlconv_nfc : 5
net_function : GELU
kernel_thresholding : 0
fixed_kernels : None
motif_cutoff : None
warm_start : False
hot_start : False
hot_alpha : None
max_pooling : True
mean_pooling : False
weighted_pooling : False
pooling_size : 10
pooling_steps : 10
dilated_convolutions : 0
strides : 1
dilations : 1
conv_increase : 1.0
dilpooling_residual : 1
dilpooling_steps : 1
dilresidual_entire : False
dilresidual_concat : False
l_dilkernels : None
dilmax_pooling : 0
dilmean_pooling : 0
dilweighted_pooling : 0
embedding_convs : 0
n_transformer : 0
n_attention : 0
n_interpolated_conv : 0
n_hyenaconv : 0
n_distattention : 0
dim_distattention : 2.5
dim_embattention : None
sum_attention : False
attentionmax_pooling : 0
attentionweighted_pooling : 0
attentionconv_pooling : 1
transformer_convolutions : 2
trpooling_residual : 1
trpooling_steps : 1
trresidual_entire : False
trstrides : 1
trdilations : 1
trconv_dim : None
l_trkernels : 7
trmean_pooling : 0
trmax_pooling : 5
trweighted_pooling : 0
gapped_convs : None
gapconv_residual : True
gapconv_pooling : False
final_convolutions : 0
final_conv_dim : None
l_finalkernels : 4
finalmax_pooling : 0
finalmean_pooling : 0
finalweighted_pooling : 1
finalstrides : 1
finaldilations : 1
fclayer_size : 1024
nfc_layers : [3, 3, 3, 3, 3, 3, 3, 3]
nfc_residuals : 0
fc_function : GELU
layer_widening : 1.1
interaction_layer : False
neuralnetout : 0
l2reg_last : 0.0
l1reg_last : 0.0
l1_kernel : 0
batch_norm : False
conv_batch_norm : True
attention_batch_norm : False
fc_batch_norm : False
dropout : 0.0
conv_dropout : 0.0
attention_dropout : 0.0
fc_dropout : 0.1
epochs : 400
lr : 1e-05
batchsize : 64
patience : 12
init_epochs : 0
init_adjust : False
load_previous : True
device : cuda:0
checkval : True
writeloss : True
write_steps : 1
optimizer : SGD
optim_params : 0.9
optim_weight_decay : None
outclass : Linear
outname : ModelsFinal/CTCFaH3K27acaH3K36me3aH3K4me3aH33aH3K27me3aH3K4me1aATAConseq2krcomp_mh0-cv10-1_Cormsek512l19TfEXPGELUmax10rcTvlCota_tc2dNoned1s1r1l7ma5nfc3s1024cbnoTfdo0.1tr1e-05SGD0.9bs64-F
