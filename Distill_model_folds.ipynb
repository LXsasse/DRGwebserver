{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7276dced",
   "metadata": {},
   "source": [
    "# Distilling multiple models into a unified framework\n",
    "\n",
    "Here we will train a distilled model on the predictions, or mean predictions from an ensemble of models trained on different folds.\n",
    "The following steps will be used:\n",
    "1. Create Training data\n",
    "\n",
    "    a. Make predictions for original sequences\n",
    "\n",
    "    b. Generate new sequences from the genome to make predictions\n",
    "\n",
    "    c. Generate new sequences with variants\n",
    "\n",
    "2. Take the mean of created data\n",
    "3. Retrain the model, use artificial sequences for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b101e",
   "metadata": {},
   "source": [
    "## 1. Create Training data from 10 fold models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3fe73",
   "metadata": {},
   "source": [
    "### a. Make predictions for original sequences with all 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aad02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "drgclis = os.path.expanduser('~/Git/DRG/scripts/')\n",
    "\n",
    "def generate_ensemble_predictions(modeldict, input_file, outpath, device='cpu', drgclis_path=None):\n",
    "    \"\"\"\n",
    "    Generate predictions from multiple models and compute their mean.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    modeldict : dict\n",
    "        Dictionary mapping fold names to model paths\n",
    "    input_file : str\n",
    "        Path to the input file for predictions\n",
    "    outpath : str\n",
    "        Output directory for saving predictions\n",
    "    device : str, optional\n",
    "        Device to use for computations ('cpu' or 'cuda'). Default is 'cpu'\n",
    "    drgclis_path : str, optional\n",
    "        Path to DRG scripts. If None, uses the global drgclis variable\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (mean_values, columns, names) - averaged predictions and metadata\n",
    "    \"\"\"\n",
    "    if drgclis_path is None:\n",
    "        drgclis_path = drgclis\n",
    "    \n",
    "    # Generate predictions for each model\n",
    "    for fold, model in modeldict.items():\n",
    "        print(f'Processing {input_file} with model {model}')\n",
    "        # Run model\n",
    "        # keep track name files in that order because it's the same as during training.\n",
    "        os.system(f'python {drgclis_path}train_models/run_cnn_model.py {input_file} None --predictnew --cnn {model}_model_params.dat device={device} --save_predictions --outname {outpath}')\n",
    "\n",
    "    # Read in predictions from individual models and create new training set out of mean\n",
    "    values_list = []\n",
    "    prevcolumns = None\n",
    "    prevnames = None\n",
    "\n",
    "    for fold, model in modeldict.items():\n",
    "        model_basename = os.path.basename(model)\n",
    "        pred_file = f'{outpath}/from{model_basename}_predictions.npz'\n",
    "        if os.path.exists(pred_file):\n",
    "            with np.load(pred_file) as data:\n",
    "                values = data['values']\n",
    "                columns = data['columns']\n",
    "                names = data['names']\n",
    "                if len(values_list) == 0:\n",
    "                    prevcolumns = columns\n",
    "                    prevnames = names\n",
    "                if np.array_equal(columns, prevcolumns) and np.array_equal(names, prevnames):\n",
    "                    values_list.append(values)\n",
    "                else:\n",
    "                    print(f'Incompatible columns or names in {pred_file}. Skipping.')\n",
    "        else:\n",
    "            print(f'Prediction file {pred_file} not found.')\n",
    "\n",
    "    if len(values_list) > 0:\n",
    "        mean_values = np.mean(values_list, axis=0)\n",
    "        return mean_values, prevcolumns, prevnames\n",
    "    else:\n",
    "        raise ValueError(\"No valid prediction files found.\")\n",
    "\n",
    "# Set up model dictionary\n",
    "modeldict = {}\n",
    "modelpath = os.path.abspath('./models/')\n",
    "modelname = 'CTCFaH3K27acaH3K36me3aH33aH3K27me3aH3K4me1aATAConseq2krcomp_mh'\n",
    "modelsuffix = '-cv10-1_Cormsek512l19TfEXPGELUmax10rcTvlCota_tc2dNoned1s1r1l7ma5nfc3s1024cbnoTfdo0.1tr1e-05SGD0.9bs64-F'\n",
    "\n",
    "for f in range(10):\n",
    "    modeldict['fold'+str(f)] = f'{modelpath}/{modelname}{f}{modelsuffix}'\n",
    "\n",
    "# Set up paths and parameters\n",
    "input_path = os.path.expanduser('./')\n",
    "input_file = f'{input_path}seq2k.npz'\n",
    "device = 'cpu'\n",
    "outpath = os.path.expanduser('./output/')\n",
    "\n",
    "# Generate ensemble predictions\n",
    "mean_values, columns, names = generate_ensemble_predictions(\n",
    "    modeldict, input_file, outpath, device=device, drgclis_path=drgclis\n",
    ")\n",
    "\n",
    "# Save the averaged predictions\n",
    "np.savez_compressed(f'{outpath}/mean_predictions.npz', \n",
    "                   counts=mean_values, \n",
    "                   celltypes=columns, \n",
    "                   names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f96000",
   "metadata": {},
   "source": [
    "### b. Generate new sequences from the genome and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin bed original bed file\n",
    "data_path = '/home/sasse/UW/CutandRun/'\n",
    "bed_file = f'{data_path}ImmGen_ATACpeak.final.bed6'\n",
    "# Read bed and create novel 250bp region that are outside the 250 regions in the bed file\n",
    "def determine_regions_between_peaks(bed_file):\n",
    "    with open(bed_file, 'r') as f:\n",
    "        peaks = [line.strip().split('\\t') for line in f.readlines()]\n",
    "    # Convert to intervals for each chromosome separately\n",
    "    intervals = {}\n",
    "    for peak in peaks:\n",
    "        chrom = peak[0]\n",
    "        start = int(peak[1])\n",
    "        end = int(peak[2])\n",
    "        if chrom not in intervals:\n",
    "            intervals[chrom] = []\n",
    "        intervals[chrom].append((start, end))\n",
    "    # Find regions between peaks for each chromosome\n",
    "    regions = {}\n",
    "    for chrom, chrom_intervals in intervals.items():\n",
    "        for i in range(len(chrom_intervals) - 1):\n",
    "            end_current = chrom_intervals[i][1]\n",
    "            start_next = chrom_intervals[i + 1][0]\n",
    "            if start_next - end_current > 250:\n",
    "                if chrom not in regions:\n",
    "                    regions[chrom] = []\n",
    "                regions[chrom].append((end_current, start_next))\n",
    "    return regions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240804a",
   "metadata": {},
   "source": [
    "### c. Generate new sequences with variants in original sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
